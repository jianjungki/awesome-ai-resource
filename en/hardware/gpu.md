| GPU Model | FP64 TFLOPS | FP32 TFLOPS | TF32 TFLOPS | FP16 TFLOPS (Tensor) | FP8 TFLOPS |  INT8 TOPS (Tensor) |FP4 TFLOPS | TDP (W) | VRAM | Architecture |
|-----------|-------------|-------------|----------------------|--------------------|---------|-------------|-------------|-------------|-------------|-------------|
| NVIDIA B200 (SXM) | 90 | 180 | 1250 | 2500 | 5000 | 10000  | 5000 | 1000 | 192GB | Blackwell |
| NVIDIA H200 (SXM) | 67 | - | 989 |1979 | 3958 | 3958 | -  | 700 | 80GB | Hopper |
| NVIDIA H100 (SXM) | 67 | - | 989 | 1979 | 3958 | 3958 |  -  | 700 | 141GB | Hopper  |
| NVIDIA H800 (SXM) | 34 | - | 495 | 990 | 1980 | 1980 | -  |  700 | 80GB | Hopper |
| NVIDIA A100 (SXM) | 19.5| -  | 156 | 312 | - | 624 | -  | 400 | 40GB/80GB | Ampere  |
| NVIDIA A6000 | - | 38.7 | 77.4 | 154.8 | - | 309.7 |  -  | 300 | 48GB | Ampere  |
| NVIDIA A40 | - | 37.4 | 74.8 | 149.7 | - | 299.3 |  -  | 300 | 48GB | Ampere  |
| NVIDIA A10 | - | 31.2 | 62.5 | 125 | - | 250 |  -  | 150 | 24GB | Ampere  |
| NVIDIA RTX 4090 | 1.29 | 82.6 | 82.6 | 165.2 | 330.3 | 330.3 |  -  | 450 | 24GB | Ada  |
| NVIDIA RTX 6000 | 1.42 | 91.1 | 45.5 | 91.1 | 182.2 | 364.4 |  -  | 300 | 48GB | Ada  |
| NVIDIA V100S | 8.2 | 16.4 | - | 32.8 | - | 260 |  -  | 250 | 32GB | Volta  |
| NVIDIA V100 | 7.8 | 15.7 | - | 31.4 | - | 250 |  -  | 300 | 16GB/32GB | Volta  |



Ampere with BF16/TF32
Hopper with FP8



For China:

Without 
NVIDIA A100、H100、A800、H800、L40、L40S、RTX 4090